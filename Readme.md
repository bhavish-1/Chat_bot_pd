Conversational RAG App for PDF QA
Personal Project

A full-stack Retrieval-Augmented Generation (RAG) application that answers context-aware questions from uploaded PDF documents.

Tech Stack
LLM Integration: Groq API with Gemma-2b

Frameworks: LangChain, ChromaDB, HuggingFace Transformers

Frontend: Streamlit

Containerization: Docker

Features
Built an end-to-end RAG pipeline using LangChain and Groq API (Gemma-2b) to enable context-based question answering from PDF documents.

Implemented document chunking, embedding generation using HuggingFace models, and semantic similarity retrieval via ChromaDB.

Integrated context-aware summarization and persistent chat history for enhanced UX.

Containerized the entire application using Docker for portability and cloud deployment.